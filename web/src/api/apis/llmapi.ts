/* tslint:disable */
/* eslint-disable */
/**
 * ApeRAG API
 * ApeRAG API Documentation
 *
 * The version of the OpenAPI document: 1.0.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import type { Configuration } from '../configuration';
import type { AxiosPromise, AxiosInstance, RawAxiosRequestConfig } from 'axios';
import globalAxios from 'axios';
// Some imports not used depending on template conditions
// @ts-ignore
import { DUMMY_BASE_URL, assertParamExists, setApiKeyToObject, setBasicAuthToObject, setBearerAuthToObject, setOAuthToObject, setSearchParams, serializeDataIfNeeded, toPathString, createRequestFunction } from '../common';
// @ts-ignore
import { BASE_PATH, COLLECTION_FORMATS, type RequestArgs, BaseAPI, RequiredError, operationServerMap } from '../base';
// @ts-ignore
import type { EmbeddingRequest } from '../models';
// @ts-ignore
import type { EmbeddingResponse } from '../models';
// @ts-ignore
import type { FailResponse } from '../models';
// @ts-ignore
import type { RerankRequest } from '../models';
// @ts-ignore
import type { RerankResponse } from '../models';
/**
 * LLMApi - axios parameter creator
 * @export
 */
export const LLMApiAxiosParamCreator = function (configuration?: Configuration) {
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {EmbeddingRequest} embeddingRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        embeddingsPost: async (embeddingRequest: EmbeddingRequest, options: RawAxiosRequestConfig = {}): Promise<RequestArgs> => {
            // verify required parameter 'embeddingRequest' is not null or undefined
            assertParamExists('embeddingsPost', 'embeddingRequest', embeddingRequest)
            const localVarPath = `/embeddings`;
            // use dummy base URL string because the URL constructor only accepts absolute URLs.
            const localVarUrlObj = new URL(localVarPath, DUMMY_BASE_URL);
            let baseOptions;
            if (configuration) {
                baseOptions = configuration.baseOptions;
            }

            const localVarRequestOptions = { method: 'POST', ...baseOptions, ...options};
            const localVarHeaderParameter = {} as any;
            const localVarQueryParameter = {} as any;

            // authentication CookieAuth required

            // authentication BearerAuth required
            // http bearer authentication required
            await setBearerAuthToObject(localVarHeaderParameter, configuration)


    
            localVarHeaderParameter['Content-Type'] = 'application/json';

            setSearchParams(localVarUrlObj, localVarQueryParameter);
            let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
            localVarRequestOptions.headers = {...localVarHeaderParameter, ...headersFromBaseOptions, ...options.headers};
            localVarRequestOptions.data = serializeDataIfNeeded(embeddingRequest, localVarRequestOptions, configuration)

            return {
                url: toPathString(localVarUrlObj),
                options: localVarRequestOptions,
            };
        },
        /**
         * Rerank a list of documents based on their relevance to a given query using the specified  provider and model. This endpoint follows the industry-standard rerank API format used by providers like Cohere, Jina AI, and others.  The endpoint supports both simple text lists and structured document objects with metadata. Documents are returned ordered by relevance score (highest first), with optional top_k  filtering to limit the number of results.  The provider must be configured in the user\'s Model Service Provider (MSP) settings with a valid API key and support rerank functionality. 
         * @summary Rerank documents
         * @param {RerankRequest} rerankRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        rerankPost: async (rerankRequest: RerankRequest, options: RawAxiosRequestConfig = {}): Promise<RequestArgs> => {
            // verify required parameter 'rerankRequest' is not null or undefined
            assertParamExists('rerankPost', 'rerankRequest', rerankRequest)
            const localVarPath = `/rerank`;
            // use dummy base URL string because the URL constructor only accepts absolute URLs.
            const localVarUrlObj = new URL(localVarPath, DUMMY_BASE_URL);
            let baseOptions;
            if (configuration) {
                baseOptions = configuration.baseOptions;
            }

            const localVarRequestOptions = { method: 'POST', ...baseOptions, ...options};
            const localVarHeaderParameter = {} as any;
            const localVarQueryParameter = {} as any;

            // authentication CookieAuth required

            // authentication BearerAuth required
            // http bearer authentication required
            await setBearerAuthToObject(localVarHeaderParameter, configuration)


    
            localVarHeaderParameter['Content-Type'] = 'application/json';

            setSearchParams(localVarUrlObj, localVarQueryParameter);
            let headersFromBaseOptions = baseOptions && baseOptions.headers ? baseOptions.headers : {};
            localVarRequestOptions.headers = {...localVarHeaderParameter, ...headersFromBaseOptions, ...options.headers};
            localVarRequestOptions.data = serializeDataIfNeeded(rerankRequest, localVarRequestOptions, configuration)

            return {
                url: toPathString(localVarUrlObj),
                options: localVarRequestOptions,
            };
        },
    }
};

/**
 * LLMApi - functional programming interface
 * @export
 */
export const LLMApiFp = function(configuration?: Configuration) {
    const localVarAxiosParamCreator = LLMApiAxiosParamCreator(configuration)
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {EmbeddingRequest} embeddingRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        async embeddingsPost(embeddingRequest: EmbeddingRequest, options?: RawAxiosRequestConfig): Promise<(axios?: AxiosInstance, basePath?: string) => AxiosPromise<EmbeddingResponse>> {
            const localVarAxiosArgs = await localVarAxiosParamCreator.embeddingsPost(embeddingRequest, options);
            const localVarOperationServerIndex = configuration?.serverIndex ?? 0;
            const localVarOperationServerBasePath = operationServerMap['LLMApi.embeddingsPost']?.[localVarOperationServerIndex]?.url;
            return (axios, basePath) => createRequestFunction(localVarAxiosArgs, globalAxios, BASE_PATH, configuration)(axios, localVarOperationServerBasePath || basePath);
        },
        /**
         * Rerank a list of documents based on their relevance to a given query using the specified  provider and model. This endpoint follows the industry-standard rerank API format used by providers like Cohere, Jina AI, and others.  The endpoint supports both simple text lists and structured document objects with metadata. Documents are returned ordered by relevance score (highest first), with optional top_k  filtering to limit the number of results.  The provider must be configured in the user\'s Model Service Provider (MSP) settings with a valid API key and support rerank functionality. 
         * @summary Rerank documents
         * @param {RerankRequest} rerankRequest 
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        async rerankPost(rerankRequest: RerankRequest, options?: RawAxiosRequestConfig): Promise<(axios?: AxiosInstance, basePath?: string) => AxiosPromise<RerankResponse>> {
            const localVarAxiosArgs = await localVarAxiosParamCreator.rerankPost(rerankRequest, options);
            const localVarOperationServerIndex = configuration?.serverIndex ?? 0;
            const localVarOperationServerBasePath = operationServerMap['LLMApi.rerankPost']?.[localVarOperationServerIndex]?.url;
            return (axios, basePath) => createRequestFunction(localVarAxiosArgs, globalAxios, BASE_PATH, configuration)(axios, localVarOperationServerBasePath || basePath);
        },
    }
};

/**
 * LLMApi - factory interface
 * @export
 */
export const LLMApiFactory = function (configuration?: Configuration, basePath?: string, axios?: AxiosInstance) {
    const localVarFp = LLMApiFp(configuration)
    return {
        /**
         * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
         * @summary Create embeddings
         * @param {LLMApiEmbeddingsPostRequest} requestParameters Request parameters.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        embeddingsPost(requestParameters: LLMApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<EmbeddingResponse> {
            return localVarFp.embeddingsPost(requestParameters.embeddingRequest, options).then((request) => request(axios, basePath));
        },
        /**
         * Rerank a list of documents based on their relevance to a given query using the specified  provider and model. This endpoint follows the industry-standard rerank API format used by providers like Cohere, Jina AI, and others.  The endpoint supports both simple text lists and structured document objects with metadata. Documents are returned ordered by relevance score (highest first), with optional top_k  filtering to limit the number of results.  The provider must be configured in the user\'s Model Service Provider (MSP) settings with a valid API key and support rerank functionality. 
         * @summary Rerank documents
         * @param {LLMApiRerankPostRequest} requestParameters Request parameters.
         * @param {*} [options] Override http request option.
         * @throws {RequiredError}
         */
        rerankPost(requestParameters: LLMApiRerankPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<RerankResponse> {
            return localVarFp.rerankPost(requestParameters.rerankRequest, options).then((request) => request(axios, basePath));
        },
    };
};

/**
 * LLMApi - interface
 * @export
 * @interface LLMApi
 */
export interface LLMApiInterface {
    /**
     * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
     * @summary Create embeddings
     * @param {LLMApiEmbeddingsPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof LLMApiInterface
     */
    embeddingsPost(requestParameters: LLMApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<EmbeddingResponse>;

    /**
     * Rerank a list of documents based on their relevance to a given query using the specified  provider and model. This endpoint follows the industry-standard rerank API format used by providers like Cohere, Jina AI, and others.  The endpoint supports both simple text lists and structured document objects with metadata. Documents are returned ordered by relevance score (highest first), with optional top_k  filtering to limit the number of results.  The provider must be configured in the user\'s Model Service Provider (MSP) settings with a valid API key and support rerank functionality. 
     * @summary Rerank documents
     * @param {LLMApiRerankPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof LLMApiInterface
     */
    rerankPost(requestParameters: LLMApiRerankPostRequest, options?: RawAxiosRequestConfig): AxiosPromise<RerankResponse>;

}

/**
 * Request parameters for embeddingsPost operation in LLMApi.
 * @export
 * @interface LLMApiEmbeddingsPostRequest
 */
export interface LLMApiEmbeddingsPostRequest {
    /**
     * 
     * @type {EmbeddingRequest}
     * @memberof LLMApiEmbeddingsPost
     */
    readonly embeddingRequest: EmbeddingRequest
}

/**
 * Request parameters for rerankPost operation in LLMApi.
 * @export
 * @interface LLMApiRerankPostRequest
 */
export interface LLMApiRerankPostRequest {
    /**
     * 
     * @type {RerankRequest}
     * @memberof LLMApiRerankPost
     */
    readonly rerankRequest: RerankRequest
}

/**
 * LLMApi - object-oriented interface
 * @export
 * @class LLMApi
 * @extends {BaseAPI}
 */
export class LLMApi extends BaseAPI implements LLMApiInterface {
    /**
     * Generate embeddings for the given input text(s) using the specified provider and model. This endpoint is compatible with OpenAI\'s embeddings API format, but includes an additional \'provider\' parameter to specify which LLM provider to use.  The endpoint supports both single text inputs and batch processing of multiple texts. It requires the provider to be configured in the user\'s Model Service Provider (MSP) settings with a valid API key. 
     * @summary Create embeddings
     * @param {LLMApiEmbeddingsPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof LLMApi
     */
    public embeddingsPost(requestParameters: LLMApiEmbeddingsPostRequest, options?: RawAxiosRequestConfig) {
        return LLMApiFp(this.configuration).embeddingsPost(requestParameters.embeddingRequest, options).then((request) => request(this.axios, this.basePath));
    }

    /**
     * Rerank a list of documents based on their relevance to a given query using the specified  provider and model. This endpoint follows the industry-standard rerank API format used by providers like Cohere, Jina AI, and others.  The endpoint supports both simple text lists and structured document objects with metadata. Documents are returned ordered by relevance score (highest first), with optional top_k  filtering to limit the number of results.  The provider must be configured in the user\'s Model Service Provider (MSP) settings with a valid API key and support rerank functionality. 
     * @summary Rerank documents
     * @param {LLMApiRerankPostRequest} requestParameters Request parameters.
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof LLMApi
     */
    public rerankPost(requestParameters: LLMApiRerankPostRequest, options?: RawAxiosRequestConfig) {
        return LLMApiFp(this.configuration).rerankPost(requestParameters.rerankRequest, options).then((request) => request(this.axios, this.basePath));
    }
}

